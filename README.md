# ğŸ“Š Customer Churn Analysis â€” End-to-End Project

## ğŸš€ Project Overview
This project demonstrates a **full Data Science & Machine Learning workflow** for predicting customer churn (e.g., Telecom/Banking).  
It includes:
- Data Cleaning & Preprocessing  
- Exploratory Data Analysis (EDA)  
- Machine Learning Models (Logistic Regression, Random Forest, XGBoost)  
- Model Deployment via **Flask API**  
- Interactive Dashboard via **Streamlit App**

The goal: help businesses **identify customers likely to churn** and take proactive actions.

---

## ğŸ“‚ Project Structure

```text
Customer-Churn-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw datasets (e.g., Telco-Customer-Churn.csv)
â”‚   â”œâ”€â”€ cleaned/              # Cleaned datasets ready for analysis
â”‚   â””â”€â”€ analysis/             # EDA outputs, charts, summaries, and predictions_for_tableau.csv
â”‚       â”œâ”€â”€ charts/           # PNG/SVG screenshots of EDA plots
â”‚       â”œâ”€â”€ summaries/        # CSV/JSON summary tables (e.g., aggregations)
â”‚       â””â”€â”€ predictions_for_tableau.csv
â”‚
â”œâ”€â”€ notebooks/                # Jupyter Notebooks (Phase 1â€“3)
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â””â”€â”€ 03_modeling.ipynb
â”‚
â”œâ”€â”€ models/                   # Saved models + feature columns
â”‚   â”œâ”€â”€ churn_model_xgb.pkl           # XGBoost final model (example)
â”‚   â”œâ”€â”€ churn_model_rf.pkl            # RandomForest model (optional)
â”‚   â”œâ”€â”€ churn_model_pipeline.pkl      # Pipeline (preprocessor + estimator)
â”‚   â”œâ”€â”€ churn_model.pkl               # generic model file (if used)
â”‚   â”œâ”€â”€ feature_cols.json             # final encoded feature column order (used for inference)
â”‚   â””â”€â”€ feature_cols_encoded.json     # optional: list of post-encoding column names
â”‚
â”œâ”€â”€ app.py                    # Flask API (Phase 4) â€” serves /ping and /predict
â”œâ”€â”€ streamlit_app.py          # Streamlit dashboard (EDA + Prediction)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Procfile                  # For Render deployment (Flask)
â””â”€â”€ README.md                 # This documentation


---

```

## ğŸ—ï¸ Phases Breakdown

### **Phase 1 â€” Data Preparation**
- Load raw dataset (`Telco-Customer-Churn.csv`)
- Handle missing values
- Encode categorical variables
- Save cleaned dataset â†’ `data/cleaned/Telco-Customer-Churn.csv`



---

### **Phase 2 â€” Exploratory Data Analysis (EDA)**
- Visualized churn distribution
- Relationship between **tenure, monthly charges, contract type** and churn
- Correlation heatmaps

 
---

### **Phase 3 â€” Modeling**
- Tried multiple models:
  - Logistic Regression
  - Random Forest
  - XGBoost (best performing)
- Hyperparameter tuning (GridSearchCV)
- Evaluated using Accuracy, Precision, Recall, F1, ROC-AUC
- Saved final model + features:
  - `models/churn_model_xgb.pkl`
  - `models/feature_cols.json`
    

---

### **Phase 4 â€” Deployment**

#### **Flask API**
- `app.py` exposes:
  - `/ping` â†’ health check  
  - `/predict` â†’ returns churn predictions + probabilities

**Run locally:**
```bash
pip install -r requirements.txt
python app.py

```

 API runs at â†’ http://localhost:8000

## Sample Request (curl):
 
 
  curl -X POST http://localhost:8000/predict \
     -H "Content-Type: application/json" \
     -d '{"tenure": 12, "MonthlyCharges": 70, "Contract": "Month-to-month", "PaymentMethod": "Electronic check"}'

 ## Response:
  
  {
  "predictions": [1],
  "probabilities": [0.82]
}

## Streamlit App

streamlit_app.py provides:

EDA Insights tab (churn charts, contract analysis, tenure distribution)

Prediction tab (single + batch prediction)

Run locally:
streamlit run streamlit_app.py

## ğŸŒ Deployment
Flask API â†’ deployed on Render

Live:  https://customer-churn-analysis-1-o034.onrender.com/

Streamlit App â†’ deployed on Streamlit Cloud

Live: https://customer-churn-analysis-6sxepmjiqkuyauabkgngme.streamlit.app/ 

## âš¡ Key Skills Demonstrated: 

Data Cleaning & Preprocessing (pandas, sklearn)

Exploratory Data Analysis (matplotlib, seaborn)

Machine Learning (Logistic Regression, Random Forest, XGBoost)

Model Saving & Loading (joblib, pickle)

API Development (Flask, gunicorn, flask-cors)

Dashboard Development (Streamlit)

Cloud Deployment (Render + Streamlit Cloud)

---

## How to Reproduce

``

1- Clone repo:

            git clone <repo-url>
            cd Customer-Churn-Analysis

 2- Install requirements:  

             pip install -r requirements.txt

3- Run notebooks step by step for Phase 1â€“3

4-Start Flask API or Streamlit app for Phase 4

---

## Future Improvements
Add AutoML for better model selection

Connect to live database (PostgreSQL / MySQL)

Integrate alerts for high churn risk customers

Add authentication for API

## Demo Screenshots

1- EDA Insights tab

  <img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/86a4fc63-11dd-4651-abdd-d1dbf783f0f8" />
  
  <img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/96561dfa-4184-48a2-a78d-cd43ea2dda26" />

  <img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/8b398ed9-8be9-4968-87aa-d2cb20677503" />

  <img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/d6930470-b541-4876-9ed4-d23d7cbbdbd6" />

---

## ğŸŒ Live Demo

 [![Streamlit Dashboard](https://img.shields.io/badge/Streamlit-Dashboard-orange?style=for-the-badge&logo=streamlit)](https://customer-churn-analysis-6sxepmjiqkuyauabkgngme.streamlit.app/)

 [![Flask API](https://img.shields.io/badge/Flask-API-blue?style=for-the-badge&logo=flask)](https://customer-churn-analysis-1-o034.onrender.com/)

 ---
 
 ## ğŸ‘¨â€ğŸ’» About the Author

# Hrithik Deep
ğŸ“ Aspiring Data Analyst / Data Scientist

---

## ğŸŒ Connect with me

[![GitHub](https://img.shields.io/badge/GitHub-Hrithikdeep-black?style=for-the-badge&logo=github)](https://github.com/Hrithikdeep)  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-YourLinkedIn-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/hrithikdeep/)  
[![Email](https://img.shields.io/badge/Email-hrithikdeep.ds@gmail.com-red?style=for-the-badge&logo=gmail)](hrithikdeep.ds@gmail.com)

---

## â­ Acknowledgments

Dataset: Telco Customer Churn Dataset (Kaggle)

Libraries: pandas, seaborn, scikit-learn, XGBoost, Flask, Streamlit


     









